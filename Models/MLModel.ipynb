{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8233240601122881\n",
      "passing_tds: 0.6192048727596294\n",
      "rushing_yards: 0.1217010158109961\n",
      "passing_yards: 0.1003088022818382\n",
      "rushing_tds: 0.07484259349104311\n",
      "carries: 0.06749521774092547\n",
      "rushing_first_downs: 0.04363696678694111\n",
      "passing_first_downs: 0.022351542322962728\n",
      "interceptions: 0.021162773355326153\n",
      "passing_yards_after_catch: 0.004558965735700322\n",
      "passing_air_yards: 0.004296417269634517\n",
      "wrte: 0.0025165754409116324\n",
      "passing_2pt_conversions: 0.0012646738029027027\n",
      "sack_fumbles_lost: 0.0010871431972547107\n",
      "rb: 0.0007374851767156366\n",
      "rushing_fumbles_lost: 0.00048708601980088637\n",
      "age: 0.00010132303627858885\n",
      "dst: 6.456436609480364e-05\n",
      "rushing_2pt_conversions: 2.431744543698877e-05\n",
      "oline: -0.0001664690943896252\n",
      "qb: -0.000342304995655478\n",
      "completions: -0.00045558710200361283\n",
      "attempts: -0.0019996641394519144\n",
      "sacks: -0.0031175292725053707\n",
      "qb score(ppg off on average per player):  0.032919317468865575\n",
      "0.8260381425104405\n",
      "passing_tds: 0.6201188144338456\n",
      "rushing_yards: 0.11785060380472957\n",
      "passing_yards: 0.09954936183632226\n",
      "rushing_tds: 0.07587801401629175\n",
      "rushing_first_downs: 0.057226887282716785\n",
      "carries: 0.05632774517079347\n",
      "passing_first_downs: 0.02216832384915362\n",
      "interceptions: 0.021030945483498334\n",
      "passing_yards_after_catch: 0.004428072202326095\n",
      "passing_air_yards: 0.004001100188470445\n",
      "wrte: 0.001337742624625755\n",
      "passing_2pt_conversions: 0.0012023950598138034\n",
      "sack_fumbles_lost: 0.0011197628292864293\n",
      "qb: 0.001024364959339913\n",
      "rb: 0.0003552797458094992\n",
      "rushing_fumbles_lost: 0.00027957068721326083\n",
      "dst: 9.894154807474353e-05\n",
      "rushing_2pt_conversions: 4.198986521698034e-05\n",
      "oline: -1.0601490185002671e-06\n",
      "completions: -0.0006098159518463897\n",
      "age: -0.000787983824377757\n",
      "attempts: -0.0019857515775214473\n",
      "sacks: -0.0029824468005345615\n",
      "qb score(ppg off on average per player):  0.03332352440615317\n",
      "0.8277672724063512\n",
      "passing_tds: 0.6230363938719294\n",
      "rushing_yards: 0.11345943162598798\n",
      "passing_yards: 0.10762469947583848\n",
      "rushing_tds: 0.07198820778642369\n",
      "carries: 0.05577618309800378\n",
      "rushing_first_downs: 0.05273025209280575\n",
      "passing_first_downs: 0.022958957564588333\n",
      "interceptions: 0.021189665644435394\n",
      "passing_yards_after_catch: 0.005241250677221368\n",
      "passing_air_yards: 0.003778684098130923\n",
      "sack_fumbles_lost: 0.002835068257825011\n",
      "wrte: 0.0017715808329951043\n",
      "passing_2pt_conversions: 0.0014741008097782105\n",
      "age: 0.001372210664431084\n",
      "oline: 0.0004739770246213215\n",
      "rb: 0.00021744602823435156\n",
      "rushing_fumbles_lost: 7.658815859774237e-05\n",
      "rushing_2pt_conversions: -2.8823868552320108e-05\n",
      "qb: -0.0001929132823589419\n",
      "dst: -0.0006686760868771013\n",
      "completions: -0.0009164142807903586\n",
      "attempts: -0.0017764433669651659\n",
      "sacks: -0.0026850097385857784\n",
      "qb score(ppg off on average per player):  0.03358262061912536\n"
     ]
    }
   ],
   "source": [
    "#QB ML MODEL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "\n",
    "#scaler to scale data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#read csv files into pandas\n",
    "dfFantasy = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_qb_data.csv\")\n",
    "dfFantasy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "numeric_cols = dfFantasy.select_dtypes(include=[np.number]).columns\n",
    "for column in numeric_cols:\n",
    "    dfFantasy[column].fillna(dfFantasy[column].mean(), inplace=True)\n",
    "dfGrades = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/approximate value data/AVbyPositionGroup.csv\")\n",
    "\n",
    "def correctData(df, pprTF):\n",
    "  #cols to make per game\n",
    "  cols = ['completions', 'attempts', 'passing_yards',\n",
    "       'passing_tds', 'interceptions', 'sacks',\n",
    "       'sack_fumbles_lost', 'passing_air_yards', 'passing_yards_after_catch',\n",
    "       'passing_first_downs', 'passing_2pt_conversions',\n",
    "       'carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "       'rushing_2pt_conversions', 'fantasy_points', 'age']\n",
    "\n",
    "  #basing data if ppr or not\n",
    "  if pprTF == 2:\n",
    "    pass\n",
    "  elif pprTF == 0:\n",
    "    pass\n",
    "  elif pprTF == 1:\n",
    "    pass\n",
    "\n",
    "    \n",
    "  #adding ppg column\n",
    "  df.loc[:, 'PPG'] = df['fantasy_points'] / df['GP']\n",
    "\n",
    "\n",
    "  #make all columns in a per game basis\n",
    "  for col in cols:\n",
    "    df.loc[:, col] = df[col] / df['GP'] \n",
    "\n",
    "\n",
    "  #only players with more than 7 games.\n",
    "  df = df[df.GP > 7]\n",
    "  df = df[df.fantasy_points >= 0]\n",
    "\n",
    "  df = df[df.PPG > 5]\n",
    "  \n",
    "\n",
    "  return df\n",
    "\n",
    "#removes unneccesary stats\n",
    "def removeUnwanted(dfPos, pos):\n",
    "  dfPos = dfPos.drop(columns=['season',\"GP\", \"season_type\", \"fantasy_points\", \"player_display_name\", \"player_id\", \"team\", \"position\"])\n",
    "  return dfPos\n",
    "\n",
    "#shifts data forward one year\n",
    "def makeCorrectShift(df):\n",
    "  shifters = ['PPG','season','GP','season_type','age','fantasy_points','completions','attempts','passing_yards','passing_tds','interceptions','sacks','sack_fumbles_lost','passing_air_yards','passing_yards_after_catch','passing_first_downs','passing_2pt_conversions','carries','rushing_yards','rushing_tds','rushing_fumbles_lost','rushing_first_downs','rushing_2pt_conversions']\n",
    "  \n",
    "  #adds target variable\n",
    "  df[\"PPG\"] = df[\"PPG\"]\n",
    "  \n",
    "  #shifts it forward a year (for example 2011 goes to 2012)\n",
    "  df[shifters] = df.groupby('player_display_name')[shifters].shift(1)\n",
    "  df = df.dropna()\n",
    "\n",
    "  return df\n",
    "\n",
    "#where machine learning is done. returns the model and score.\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def machineLearning(df, arr, dictParam):\n",
    "    # Define predictors excluding the target variable\n",
    "    predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "\n",
    "    # Split the data\n",
    "    x = df[predictors].values\n",
    "    y = df[\"PPG\"].values\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Initialize and train GradientBoostingRegressor\n",
    "    gbr = GradientBoostingRegressor(**dictParam)\n",
    "    gbr.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predict_test = gbr.predict(x_test)\n",
    "    mae = mean_absolute_error(y_test, predict_test)\n",
    "\n",
    "    predict_test_unscaled = predict_test * (arr[1] - arr[0]) + arr[0]\n",
    "    y_test_unscaled = y_test * (arr[1] - arr[0]) + arr[0]\n",
    "\n",
    "    # Calculate permutation importance\n",
    "    r = permutation_importance(gbr, x_test, y_test, n_repeats=100, random_state=0)\n",
    "\n",
    "    # Organize importances\n",
    "    importance_dict = {name: score for name, score in zip(predictors, r.importances_mean)}\n",
    "    sorted_importances = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for feature, importance in sorted_importances:\n",
    "      print(f\"{feature}: {importance}\")\n",
    "\n",
    "\n",
    "    return [mae, gbr]\n",
    "\n",
    "# Example usage of the modified function\n",
    "\n",
    "\n",
    "def getBestParams(df, arr):\n",
    "\n",
    "  #make the predictors and data and test sets correctly\n",
    "  predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "  x = df[predictors].values\n",
    "  y = df[\"PPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  \n",
    "  #make the parameters to search over. for hidden_layer_sizes, I experimented with alot and the ones listed now is just final set of experiment.\n",
    "  \n",
    "  grid = {\n",
    "      'n_estimators': [100, 200, 300],\n",
    "      'learning_rate': [0.01, 0.1, 0.2],\n",
    "      'max_depth': [3, 4, 5],\n",
    "      'min_samples_split': [2, 3, 4]\n",
    "  }\n",
    "\n",
    "  #create an MLPRegressor object\n",
    "  gbr = GradientBoostingRegressor()\n",
    "\n",
    "  #create a GridSearchCV object and fit it to the training data\n",
    "  grid_search = GridSearchCV(gbr, param_grid=grid, cv=5, n_jobs=-1)\n",
    "  grid_search.fit(x_train, y_train)\n",
    "\n",
    "  #the best model to make predictions on the test data and evaluate performance\n",
    "  y_pred = grid_search.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale, uses a reverse of original formula\n",
    "  for i in range(len(y_pred)):\n",
    "    y_pred[i] = (y_pred[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "\n",
    "  print(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "  return grid_search.best_params_\n",
    "\n",
    "#gets original value for fantasy points for predictions.\n",
    "def getScaleBack(df):\n",
    "  #index of column\n",
    "  column_index = df.columns.get_loc(\"PPG\")\n",
    "\n",
    "  #min value of column:\n",
    "  min_value = df[\"PPG\"].min()\n",
    "\n",
    "  #scaling valye of column\n",
    "  #scaling_factor = scaler.scale_[column_index]\n",
    "  max_value = df[\"PPG\"].max()\n",
    "\n",
    "  #array to be used later to scale each data\n",
    "  arr = [min_value, max_value]\n",
    "\n",
    "  return arr\n",
    "\n",
    "def test(df, model, arr):\n",
    "  #make columns everything but target\n",
    "  predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "\n",
    "\n",
    "  #make train and test sets\n",
    "  x = df[predictors].values\n",
    "  y = df[\"PPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  #make the predictions\n",
    "  predict_test = model.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale by reversing formula\n",
    "  for i in range(len(predict_test)):\n",
    "    predict_test[i] = (predict_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "  #average error \n",
    "  mae = mean_absolute_error(y_test, predict_test)\n",
    "  print(\"test \", mae)\n",
    "\n",
    "#if ppr is 0, than it is non ppr. if 1, then it is half ppr. if 2, full ppr. loops through each.\n",
    "for ppr in [0,1,2]:\n",
    "\n",
    "  dfFantasyCopy = dfFantasy.copy()\n",
    "\n",
    "  dfFantasyCopy = correctData(dfFantasyCopy, ppr)\n",
    "\n",
    "  dfFantasyCopy = makeCorrectShift(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.loc[dfFantasyCopy[\"season\"] != 2012]\n",
    "\n",
    "  dfFantasyCopy = removeUnwanted(dfFantasyCopy, \"QB\")\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.reset_index(drop=True)\n",
    "\n",
    "  #gets fantasy_points_ppr scale per each position\n",
    "  scaleQB = getScaleBack(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy[dfFantasyCopy.columns] = scaler.fit_transform(dfFantasyCopy[dfFantasyCopy.columns])\n",
    "\n",
    "  #obtained by running the getBestParams function per each respective position\n",
    "  paramQB = getBestParams(dfFantasyCopy, scaleQB)\n",
    "\n",
    "  #makes array of model and score, then prints it\n",
    "  qbArray = machineLearning(dfFantasyCopy, scaleQB, paramQB)\n",
    "  num = qbArray[0]\n",
    "  qbModel = qbArray[1]\n",
    "  print(\"qb score(ppg off on average per player): \", num)\n",
    "\n",
    "  if ppr == 0:\n",
    "      joblib.dump(qbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/qb models/qbModelNonPPR.joblib\")\n",
    "  elif ppr == 1:\n",
    "      joblib.dump(qbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/qb models/qbModelHalfPPR.joblib\")\n",
    "  elif ppr == 2:\n",
    "      joblib.dump(qbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/qb models/qbModelPPR.joblib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rushing_yards: 0.1929085740021546\n",
      "rb: 0.08914506251951297\n",
      "carries: 0.04023627380623785\n",
      "rushing_first_downs: 0.020789595466894063\n",
      "rushing_fumbles_lost: 0.004206210903105381\n",
      "dst: 0.0031500468520152458\n",
      "rushing_tds: 0.0011425176894449406\n",
      "rrtd: 0.0008176672419011921\n",
      "wrte: 0.0006281850511060705\n",
      "qb: 0.0005499011217807948\n",
      "special_teams_tds: 0.00014294052556384606\n",
      "rushing_2pt_conversions: 0.0\n",
      "receiving_fumbles_lost: 0.0\n",
      "receiving_2pt_conversions: 0.0\n",
      "receiving_yards: -0.00015041789268467\n",
      "receiving_tds: -0.001011557765697708\n",
      "oline: -0.001965134681091405\n",
      "receiving_air_yards: -0.007151872987306731\n",
      "targets: -0.008103613036009484\n",
      "receiving_yards_after_catch: -0.011244571619918698\n",
      "receptions: -0.011752227122600151\n",
      "receiving_first_downs: -0.029051068994411202\n",
      "age: -0.03255925777776433\n",
      "rb score(ppg off on average per player):  0.1395971519985389\n",
      "rushing_yards: 0.2194728439894976\n",
      "rb: 0.03963803438912141\n",
      "age: 0.034746228807225235\n",
      "rushing_first_downs: 0.02495815245726284\n",
      "rrtd: 0.017823606093774015\n",
      "receiving_first_downs: 0.01695271520253638\n",
      "receiving_yards_after_catch: 0.016643789326937837\n",
      "rushing_tds: 0.015171061148289887\n",
      "receptions: 0.015053540559132092\n",
      "carries: 0.010693005228660466\n",
      "rushing_fumbles_lost: 0.01033098977050998\n",
      "dst: 0.0040357980099506715\n",
      "receiving_yards: 0.002535358840804731\n",
      "targets: 0.0004503866605978035\n",
      "special_teams_tds: 0.0002640850768134906\n",
      "rushing_2pt_conversions: 0.0001756690702051711\n",
      "receiving_fumbles_lost: 0.0\n",
      "receiving_2pt_conversions: 0.0\n",
      "receiving_air_yards: -0.0003015891918225644\n",
      "qb: -0.0015879239303240179\n",
      "wrte: -0.002702723289457749\n",
      "receiving_tds: -0.0029865689959437613\n",
      "oline: -0.005049924477155278\n",
      "rb score(ppg off on average per player):  0.12687197889577317\n",
      "rushing_yards: 0.1381998519732931\n",
      "rushing_first_downs: 0.08974453692636977\n",
      "rrtd: 0.025207573901662315\n",
      "rb: 0.024147629297744107\n",
      "oline: 0.012640432005596995\n",
      "receiving_yards_after_catch: 0.011565131501108628\n",
      "qb: 0.008676544154116532\n",
      "wrte: 0.0069514262797735335\n",
      "receiving_first_downs: 0.0061891733581690145\n",
      "age: 0.0024418105259304533\n",
      "rushing_tds: 0.0023465272379969205\n",
      "carries: 0.0016855159721245916\n",
      "receiving_air_yards: 0.0016751998487157306\n",
      "dst: 0.000883481738825701\n",
      "receiving_fumbles_lost: 0.0\n",
      "receiving_2pt_conversions: 0.0\n",
      "special_teams_tds: 0.0\n",
      "receiving_tds: -0.00018212437656959236\n",
      "targets: -0.0021506977854606323\n",
      "rushing_2pt_conversions: -0.002893004914064797\n",
      "receiving_yards: -0.004814752349440978\n",
      "rushing_fumbles_lost: -0.006326551044854054\n",
      "receptions: -0.00762027589631801\n",
      "rb score(ppg off on average per player):  0.12353081476576472\n"
     ]
    }
   ],
   "source": [
    "#RB ML MODEL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "\n",
    "#scaler to scale data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#read csv files into pandas\n",
    "dfFantasy = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_rb_data.csv\")\n",
    "dfFantasy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "numeric_cols = dfFantasy.select_dtypes(include=[np.number]).columns\n",
    "for column in numeric_cols:\n",
    "    dfFantasy[column].fillna(dfFantasy[column].mean(), inplace=True)\n",
    "dfGrades = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/approximate value data/AVbyPositionGroup.csv\")\n",
    "\n",
    "def correctData(df, pprTF):\n",
    "  #cols to make per game\n",
    "  cols = ['carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs', 'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs',\n",
    "       'receiving_2pt_conversions', 'special_teams_tds', 'fantasy_points', 'rrtd', 'age']\n",
    "\n",
    "  #basing data if ppr or not\n",
    "  if pprTF == 2:\n",
    "    pass\n",
    "  elif pprTF == 0:\n",
    "    df.loc[:, \"fantasy_points\"] = df[\"fantasy_points\"] - df[\"receptions\"]\n",
    "  elif pprTF == 1:\n",
    "    df.loc[:, \"fantasy_points\"] = df[\"fantasy_points\"] - (df[\"receptions\"]/2)\n",
    "\n",
    "    \n",
    "  #adding ppg column\n",
    "  df.loc[:, 'PPG'] = df['fantasy_points'] / df['GP']\n",
    "\n",
    "\n",
    "  #make all columns in a per game basis\n",
    "  for col in cols:\n",
    "    df.loc[:, col] = df[col] / df['GP'] \n",
    "\n",
    "\n",
    "  #only players with more than 7 games.\n",
    "  df = df[df.GP > 7]\n",
    "  df = df[df.fantasy_points >= 0]\n",
    "\n",
    "  df = df[df.PPG > 2]\n",
    "  \n",
    "\n",
    "  return df\n",
    "\n",
    "#removes unneccesary stats\n",
    "def removeUnwanted(dfPos, pos):\n",
    "  dfPos = dfPos.drop(columns=['season',\"GP\", \"season_type\", \"fantasy_points\", \"player_display_name\", \"player_id\", \"team\", \"position\"])\n",
    "  return dfPos\n",
    "\n",
    "#shifts data forward one year\n",
    "def makeCorrectShift(df):\n",
    "  shifters = ['player_id', 'season', 'player_display_name', 'team', 'GP', 'position',\n",
    "       'age','season_type', 'carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "       'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs',\n",
    "       'receiving_2pt_conversions', 'special_teams_tds', 'fantasy_points',\n",
    "       'rrtd']\n",
    "  \n",
    "  #adds target variable\n",
    "  df[\"PPG\"] = df[\"PPG\"]\n",
    "  \n",
    "  #shifts it forward a year (for example 2011 goes to 2012)\n",
    "  df[shifters] = df.groupby('player_display_name')[shifters].shift(1)\n",
    "  df = df.dropna()\n",
    "\n",
    "  return df\n",
    "\n",
    "#where machine learning is done. returns the model and score.\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def machineLearning(df, arr, dictParam):\n",
    "    # Define predictors excluding the target variable\n",
    "    predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "\n",
    "    # Split the data\n",
    "    x = df[predictors].values\n",
    "    y = df[\"PPG\"].values\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Initialize and train GradientBoostingRegressor\n",
    "    gbr = GradientBoostingRegressor(**dictParam)\n",
    "    gbr.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predict_test = gbr.predict(x_test)\n",
    "    mae = mean_absolute_error(y_test, predict_test)\n",
    "\n",
    "    predict_test_unscaled = predict_test * (arr[1] - arr[0]) + arr[0]\n",
    "    y_test_unscaled = y_test * (arr[1] - arr[0]) + arr[0]\n",
    "\n",
    "    # print(\"Predicted vs Actual PPG (unscaled):\")\n",
    "    # for pred, actual in zip(predict_test_unscaled, y_test_unscaled):\n",
    "    #     print(f\"Predicted: {pred:.2f}, Actual: {actual:.2f}\")\n",
    "\n",
    "    # Calculate permutation importance\n",
    "    r = permutation_importance(gbr, x_test, y_test, n_repeats=100, random_state=0)\n",
    "\n",
    "    # Organize importances\n",
    "    importance_dict = {name: score for name, score in zip(predictors, r.importances_mean)}\n",
    "    sorted_importances = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for feature, importance in sorted_importances:\n",
    "        print(f\"{feature}: {importance}\")\n",
    "    \n",
    "\n",
    "\n",
    "    return [mae, gbr, sorted_importances]\n",
    "\n",
    "# Example usage of the modified function\n",
    "\n",
    "\n",
    "def getBestParams(df, arr):\n",
    "\n",
    "  #make the predictors and data and test sets correctly\n",
    "  predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "  x = df[predictors].values\n",
    "  y = df[\"PPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  \n",
    "  #make the parameters to search over. for hidden_layer_sizes, I experimented with alot and the ones listed now is just final set of experiment.\n",
    "  \n",
    "  grid = {\n",
    "      'n_estimators': [100, 200, 300],\n",
    "      'learning_rate': [0.01, 0.1, 0.2],\n",
    "      'max_depth': [3, 4, 5],\n",
    "      'min_samples_split': [2, 3, 4]\n",
    "  }\n",
    "\n",
    "  #create an MLPRegressor object\n",
    "  gbr = GradientBoostingRegressor()\n",
    "\n",
    "  #create a GridSearchCV object and fit it to the training data\n",
    "  grid_search = GridSearchCV(gbr, param_grid=grid, cv=5, n_jobs=-1)\n",
    "  grid_search.fit(x_train, y_train)\n",
    "\n",
    "  #the best model to make predictions on the test data and evaluate performance\n",
    "  y_pred = grid_search.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale, uses a reverse of original formula\n",
    "  for i in range(len(y_pred)):\n",
    "    y_pred[i] = (y_pred[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "\n",
    "  # print(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "  return grid_search.best_params_\n",
    "\n",
    "#gets original value for fantasy points for predictions.\n",
    "def getScaleBack(df):\n",
    "  #index of column\n",
    "  column_index = df.columns.get_loc(\"PPG\")\n",
    "\n",
    "  #min value of column:\n",
    "  min_value = df[\"PPG\"].min()\n",
    "\n",
    "  #scaling valye of column\n",
    "  #scaling_factor = scaler.scale_[column_index]\n",
    "  max_value = df[\"PPG\"].max()\n",
    "\n",
    "  #array to be used later to scale each data\n",
    "  arr = [min_value, max_value]\n",
    "\n",
    "  return arr\n",
    "\n",
    "def test(df, model, arr):\n",
    "  #make columns everything but target\n",
    "  predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "\n",
    "\n",
    "  #make train and test sets\n",
    "  x = df[predictors].values\n",
    "  y = df[\"PPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  #make the predictions\n",
    "  predict_test = model.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale by reversing formula\n",
    "  for i in range(len(predict_test)):\n",
    "    predict_test[i] = (predict_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "  #average error \n",
    "  mae = mean_absolute_error(y_test, predict_test)\n",
    "  print(\"test \", mae)\n",
    "\n",
    "#if ppr is 0, than it is non ppr. if 1, then it is half ppr. if 2, full ppr. loops through each.\n",
    "for ppr in [0,1,2]:\n",
    "\n",
    "  dfFantasyCopy = dfFantasy.copy()\n",
    "\n",
    "  dfFantasyCopy = correctData(dfFantasyCopy, ppr)\n",
    "\n",
    "  dfFantasyCopy = makeCorrectShift(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.loc[dfFantasyCopy[\"season\"] != 2012]\n",
    "\n",
    "  dfFantasyCopy = removeUnwanted(dfFantasyCopy, \"RB\")\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.reset_index(drop=True)\n",
    "\n",
    "  #gets fantasy_points_ppr scale per each position\n",
    "  scaleRB = getScaleBack(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy[dfFantasyCopy.columns] = scaler.fit_transform(dfFantasyCopy[dfFantasyCopy.columns])\n",
    "\n",
    "  #obtained by running the getBestParams function per each respective position\n",
    "  paramRB = getBestParams(dfFantasyCopy, scaleRB)\n",
    "\n",
    "  #makes array of model and score, then prints it\n",
    "  rbArray = machineLearning(dfFantasyCopy, scaleRB, paramRB)\n",
    "  num = rbArray[0]\n",
    "  rbModel = rbArray[1]\n",
    "\n",
    "  print(\"rb score(ppg off on average per player): \", num)\n",
    "  if ppr == 0:\n",
    "      joblib.dump(rbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/rb models/rbModelNonPPR.joblib\")\n",
    "  elif ppr == 1:\n",
    "      joblib.dump(rbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/rb models/rbModelHalfPPR.joblib\")\n",
    "  elif ppr == 2:\n",
    "      joblib.dump(rbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/rb models/rbModelPPR.joblib\")\n",
    "#print(dfFantasyRB.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "receiving_air_yards: 0.12494293932563826\n",
      "receiving_yards_after_catch: 0.1127479736743029\n",
      "qb: 0.034549626882276085\n",
      "targets: 0.02996402787782693\n",
      "wrte: 0.027093292731436413\n",
      "oline: 0.013694663937905067\n",
      "receiving_fumbles_lost: 0.007372895496291856\n",
      "receiving_first_downs: 0.0028296287450154845\n",
      "receiving_2pt_conversions: 0.000696521726315641\n",
      "rushing_fumbles_lost: 0.0\n",
      "rushing_2pt_conversions: 0.0\n",
      "special_teams_tds: 0.0\n",
      "carries: -0.000547331074741817\n",
      "dst: -0.0007804693078689385\n",
      "rushing_first_downs: -0.0011972067100312444\n",
      "rrtd: -0.0018572005247576061\n",
      "receiving_tds: -0.004178986760477902\n",
      "receiving_yards: -0.00538779550545945\n",
      "age: -0.006479874306760797\n",
      "rushing_yards: -0.006554582648564828\n",
      "rushing_tds: -0.011670463586085778\n",
      "rb: -0.011879107921965443\n",
      "receptions: -0.0156897052963289\n",
      "wrte score(ppg off on average per player):  0.11547063182150859\n",
      "receiving_yards: 0.16085173851668422\n",
      "receiving_air_yards: 0.1428441591521972\n",
      "qb: 0.0229973405586206\n",
      "receiving_yards_after_catch: 0.02145512373717256\n",
      "wrte: 0.01660602669373682\n",
      "receiving_first_downs: 0.013976119934265431\n",
      "receptions: 0.012452129314899972\n",
      "age: 0.00806814091027974\n",
      "targets: 0.004565220591736109\n",
      "dst: 0.0037228812814645794\n",
      "oline: 0.0029438613234623024\n",
      "receiving_fumbles_lost: 0.002446880771371993\n",
      "receiving_2pt_conversions: 0.0015126185992127205\n",
      "rushing_tds: 0.0008098162723241009\n",
      "rushing_yards: 0.0006740536484197168\n",
      "rushing_fumbles_lost: 0.0001545614892065994\n",
      "rushing_2pt_conversions: 0.0\n",
      "special_teams_tds: 0.0\n",
      "carries: -3.270924792323271e-05\n",
      "rrtd: -0.001156602501418702\n",
      "rushing_first_downs: -0.0012800863629397407\n",
      "rb: -0.0015793310318646758\n",
      "receiving_tds: -0.0017832194854951822\n",
      "wrte score(ppg off on average per player):  0.11095823912480868\n",
      "receiving_yards: 0.34610381844238597\n",
      "receiving_air_yards: 0.07293469225185983\n",
      "age: 0.013705742957595959\n",
      "receptions: 0.012870482885030452\n",
      "receiving_yards_after_catch: 0.011551924252317698\n",
      "targets: 0.01146844296427048\n",
      "qb: 0.009471026655687432\n",
      "wrte: 0.00771273203872898\n",
      "rushing_yards: 0.004200889067966606\n",
      "receiving_first_downs: 0.004195236096626127\n",
      "receiving_tds: 0.00304459474209162\n",
      "carries: 0.002621133988066857\n",
      "rrtd: 0.0026156487192496958\n",
      "rb: 0.0006635909688296327\n",
      "oline: 0.0003409175391725161\n",
      "rushing_fumbles_lost: 0.0003303922914092794\n",
      "receiving_fumbles_lost: 2.7624194445334815e-05\n",
      "receiving_2pt_conversions: 1.311445343926021e-05\n",
      "rushing_2pt_conversions: 0.0\n",
      "special_teams_tds: 0.0\n",
      "rushing_first_downs: -0.00038093829148299176\n",
      "rushing_tds: -0.0010901079145494486\n",
      "dst: -0.002344795926223211\n",
      "wrte score(ppg off on average per player):  0.10710548875986883\n"
     ]
    }
   ],
   "source": [
    "#WRTE ML MODEL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "\n",
    "#scaler to scale data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#read csv files into pandas\n",
    "dfFantasy = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_wrte_data.csv\")\n",
    "dfFantasy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "numeric_cols = dfFantasy.select_dtypes(include=[np.number]).columns\n",
    "for column in numeric_cols:\n",
    "    dfFantasy[column].fillna(dfFantasy[column].mean(), inplace=True)\n",
    "dfGrades = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/approximate value data/AVbyPositionGroup.csv\")\n",
    "\n",
    "def correctData(df, pprTF):\n",
    "  #cols to make per game\n",
    "  cols = ['carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs', 'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs',\n",
    "       'receiving_2pt_conversions', 'special_teams_tds', 'fantasy_points', 'rrtd', 'age']\n",
    "\n",
    "  #basing data if ppr or not\n",
    "  if pprTF == 2:\n",
    "    pass\n",
    "  elif pprTF == 0:\n",
    "    df.loc[:, \"fantasy_points\"] = df[\"fantasy_points\"] - df[\"receptions\"]\n",
    "  elif pprTF == 1:\n",
    "    df.loc[:, \"fantasy_points\"] = df[\"fantasy_points\"] - (df[\"receptions\"]/2)\n",
    "\n",
    "    \n",
    "  #adding ppg column\n",
    "  df.loc[:, 'PPG'] = df['fantasy_points'] / df['GP']\n",
    "\n",
    "\n",
    "  #make all columns in a per game basis\n",
    "  for col in cols:\n",
    "    df.loc[:, col] = df[col] / df['GP'] \n",
    "\n",
    "\n",
    "  #only players with more than 7 games.\n",
    "  df = df[df.GP > 7]\n",
    "  df = df[df.fantasy_points >= 0]\n",
    "\n",
    "  df = df[df.PPG > 2]\n",
    "  \n",
    "\n",
    "  return df\n",
    "\n",
    "#removes unneccesary stats\n",
    "def removeUnwanted(dfPos, pos):\n",
    "  dfPos = dfPos.drop(columns=['season',\"GP\", \"season_type\", \"fantasy_points\", \"player_display_name\", \"player_id\", \"team\", \"position\"])\n",
    "  return dfPos\n",
    "\n",
    "#shifts data forward one year\n",
    "def makeCorrectShift(df):\n",
    "  shifters = ['player_id', 'season', 'player_display_name', 'team', 'GP', 'position',\n",
    "       'age', 'season_type', 'carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "       'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs',\n",
    "       'receiving_2pt_conversions', 'special_teams_tds', 'fantasy_points',\n",
    "       'rrtd']\n",
    "  \n",
    "  #adds target variable\n",
    "  df[\"PPG\"] = df[\"PPG\"]\n",
    "  \n",
    "  #shifts it forward a year (for example 2011 goes to 2012)\n",
    "  df[shifters] = df.groupby('player_display_name')[shifters].shift(1)\n",
    "  df = df.dropna()\n",
    "\n",
    "  return df\n",
    "\n",
    "#where machine learning is done. returns the model and score.\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def machineLearning(df, arr, dictParam):\n",
    "    # Define predictors excluding the target variable\n",
    "    predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "\n",
    "    # Split the data\n",
    "    x = df[predictors].values\n",
    "    y = df[\"PPG\"].values\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Initialize and train MLPRegressor\n",
    "    gbr = GradientBoostingRegressor(**dictParam)\n",
    "    gbr.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predict_test = gbr.predict(x_test)\n",
    "    mae = mean_absolute_error(y_test, predict_test)\n",
    "\n",
    "    predict_test_unscaled = predict_test * (arr[1] - arr[0]) + arr[0]\n",
    "    y_test_unscaled = y_test * (arr[1] - arr[0]) + arr[0]\n",
    "\n",
    "    # print(\"Predicted vs Actual PPG (unscaled):\")\n",
    "    # for pred, actual in zip(predict_test_unscaled, y_test_unscaled):\n",
    "    #     print(f\"Predicted: {pred:.2f}, Actual: {actual:.2f}\")\n",
    "\n",
    "    # Calculate permutation importance\n",
    "    r = permutation_importance(gbr, x_test, y_test, n_repeats=100, random_state=0)\n",
    "\n",
    "    # Organize importances\n",
    "    importance_dict = {name: score for name, score in zip(predictors, r.importances_mean)}\n",
    "    sorted_importances = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Print sorted importances\n",
    "    for feature, importance in sorted_importances:\n",
    "        print(f\"{feature}: {importance}\")\n",
    "    \n",
    "\n",
    "\n",
    "    return [mae, gbr, sorted_importances]\n",
    "\n",
    "# Example usage of the modified function\n",
    "\n",
    "\n",
    "def getBestParams(df, arr):\n",
    "\n",
    "  #make the predictors and data and test sets correctly\n",
    "  predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "  x = df[predictors].values\n",
    "  y = df[\"PPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  \n",
    "  #make the parameters to search over. for hidden_layer_sizes, I experimented with alot and the ones listed now is just final set of experiment.\n",
    "  \n",
    "  grid = {\n",
    "      'n_estimators': [100, 200, 300],\n",
    "      'learning_rate': [0.01, 0.1, 0.2],\n",
    "      'max_depth': [3, 4, 5],\n",
    "      'min_samples_split': [2, 3, 4]\n",
    "  }\n",
    "\n",
    "  #create an MLPRegressor object\n",
    "  gbr = GradientBoostingRegressor()\n",
    "\n",
    "  #create a GridSearchCV object and fit it to the training data\n",
    "  grid_search = GridSearchCV(gbr, param_grid=grid, cv=5, n_jobs=-1)\n",
    "  grid_search.fit(x_train, y_train)\n",
    "\n",
    "  #the best model to make predictions on the test data and evaluate performance\n",
    "  y_pred = grid_search.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale, uses a reverse of original formula\n",
    "  for i in range(len(y_pred)):\n",
    "    y_pred[i] = (y_pred[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "\n",
    "  # print(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "  return grid_search.best_params_\n",
    "\n",
    "#gets original value for fantasy points for predictions.\n",
    "def getScaleBack(df):\n",
    "  #index of column\n",
    "  column_index = df.columns.get_loc(\"PPG\")\n",
    "\n",
    "  #min value of column:\n",
    "  min_value = df[\"PPG\"].min()\n",
    "\n",
    "  #scaling valye of column\n",
    "  #scaling_factor = scaler.scale_[column_index]\n",
    "  max_value = df[\"PPG\"].max()\n",
    "\n",
    "  #array to be used later to scale each data\n",
    "  arr = [min_value, max_value]\n",
    "\n",
    "  return arr\n",
    "\n",
    "def test(df, model, arr):\n",
    "  #make columns everything but target\n",
    "  predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "\n",
    "\n",
    "  #make train and test sets\n",
    "  x = df[predictors].values\n",
    "  y = df[\"PPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  #make the predictions\n",
    "  predict_test = model.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale by reversing formula\n",
    "  for i in range(len(predict_test)):\n",
    "    predict_test[i] = (predict_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "  #average error \n",
    "  mae = mean_absolute_error(y_test, predict_test)\n",
    "  # print(\"test \", mae)\n",
    "\n",
    "#if ppr is 0, than it is non ppr. if 1, then it is half ppr. if 2, full ppr. loops through each.\n",
    "for ppr in [0,1,2]:\n",
    "\n",
    "  dfFantasyCopy = dfFantasy.copy()\n",
    "\n",
    "  dfFantasyCopy = correctData(dfFantasyCopy, ppr)\n",
    "  \n",
    "  dfFantasyCopy = makeCorrectShift(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.loc[dfFantasyCopy[\"season\"] != 2012]\n",
    "\n",
    "  dfFantasyCopy = removeUnwanted(dfFantasyCopy, \"WRTE\")\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.reset_index(drop=True)\n",
    "\n",
    "  #gets fantasy_points_ppr scale per each position\n",
    "  scaleWRTE = getScaleBack(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy[dfFantasyCopy.columns] = scaler.fit_transform(dfFantasyCopy[dfFantasyCopy.columns])\n",
    "\n",
    "  #obtained by running the getBestParams function per each respective position\n",
    "  paramWRTE = getBestParams(dfFantasyCopy, scaleWRTE)\n",
    "\n",
    "  #makes array of model and score, then prints it\n",
    "  wrteArray = machineLearning(dfFantasyCopy, scaleWRTE, paramWRTE)\n",
    "  num = wrteArray[0]\n",
    "  wrteModel = wrteArray[1]\n",
    "\n",
    "  print(\"wrte score(ppg off on average per player): \", num)\n",
    "  if ppr == 0:\n",
    "      joblib.dump(wrteModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/wrte models/wrteModelNonPPR.joblib\")\n",
    "  elif ppr == 1:\n",
    "      joblib.dump(wrteModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/wrte models/wrteModelHalfPPR.joblib\")\n",
    "  elif ppr == 2:\n",
    "      joblib.dump(wrteModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/wrte models/wrteModelPPR.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
