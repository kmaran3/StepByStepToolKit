{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8249424962974933\n",
      "passing_tds: 0.6266619665385622\n",
      "passing_yards: 0.0988907952525303\n",
      "rushing_yards: 0.09231895379768502\n",
      "carries: 0.07935285058211289\n",
      "rushing_tds: 0.0718703700638194\n",
      "rushing_first_downs: 0.05195962132550578\n",
      "passing_first_downs: 0.027516317260428993\n",
      "interceptions: 0.019939035370580928\n",
      "passing_yards_after_catch: 0.004137192384833498\n",
      "passing_air_yards: 0.00202327312487259\n",
      "passing_2pt_conversions: 0.0015879698827468414\n",
      "sack_fumbles_lost: 0.0014632733827842526\n",
      "qb: 0.001190850852694445\n",
      "oline: 0.0007673859619806933\n",
      "rushing_fumbles_lost: 0.0005723251541924956\n",
      "wrte: 0.0004643831881447158\n",
      "dst: 5.207888681413309e-07\n",
      "rushing_2pt_conversions: -0.00028213546292275014\n",
      "rb: -0.0005968737338998587\n",
      "age: -0.0008649252020371978\n",
      "completions: -0.0010677530583316553\n",
      "attempts: -0.0014007366948538325\n",
      "sacks: -0.002754858395207249\n",
      "qb score(ppg off on average per player):  0.03342570050181966\n",
      "0.7967349201234002\n",
      "passing_tds: 0.6162275256462472\n",
      "rushing_yards: 0.11796849697656267\n",
      "passing_yards: 0.10431631307539664\n",
      "rushing_tds: 0.07385039645648009\n",
      "carries: 0.058431242211709866\n",
      "rushing_first_downs: 0.05354876688042085\n",
      "passing_first_downs: 0.023216822872314236\n",
      "interceptions: 0.020553388498163037\n",
      "passing_yards_after_catch: 0.0050540181989458975\n",
      "passing_air_yards: 0.0036284705831861543\n",
      "qb: 0.00221892393584757\n",
      "sack_fumbles_lost: 0.0012636762735138262\n",
      "passing_2pt_conversions: 0.0012238491363420001\n",
      "rb: 0.0006321546000243028\n",
      "rushing_fumbles_lost: 0.00048102834110514304\n",
      "dst: 7.630340775194867e-05\n",
      "rushing_2pt_conversions: 3.897601429969755e-05\n",
      "oline: -0.00014139746972167578\n",
      "wrte: -0.00047321876314066256\n",
      "completions: -0.0005609305235531237\n",
      "age: -0.0006137487686590048\n",
      "attempts: -0.0020632123767380063\n",
      "sacks: -0.0030608667742439365\n",
      "qb score(ppg off on average per player):  0.03289534264704953\n",
      "0.8115999832214974\n",
      "passing_tds: 0.6157277643331536\n",
      "rushing_yards: 0.10293719527601092\n",
      "passing_yards: 0.09822853081457392\n",
      "rushing_tds: 0.06711924449316853\n",
      "carries: 0.057426619822549194\n",
      "rushing_first_downs: 0.05296179006445202\n",
      "passing_first_downs: 0.023036290888518933\n",
      "interceptions: 0.020648540510881587\n",
      "passing_air_yards: 0.0077898481290054455\n",
      "passing_yards_after_catch: 0.005254865267511385\n",
      "qb: 0.002111376545118744\n",
      "age: 0.001352409518704838\n",
      "passing_2pt_conversions: 0.001051264504536037\n",
      "sack_fumbles_lost: 0.0009763914717047684\n",
      "rushing_fumbles_lost: 0.0005111789320762571\n",
      "rb: 0.0004653109875376693\n",
      "dst: 0.00021273835313401546\n",
      "rushing_2pt_conversions: 3.684766179123944e-05\n",
      "oline: -0.00015294157013523324\n",
      "completions: -0.0006325637475088219\n",
      "wrte: -0.0008472936938648901\n",
      "sacks: -0.0010469214497948799\n",
      "attempts: -0.002027993928863682\n",
      "qb score(ppg off on average per player):  0.03300304766019611\n"
     ]
    }
   ],
   "source": [
    "#QB ML MODEL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "\n",
    "#scaler to scale data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#read csv files into pandas\n",
    "dfFantasy = pd.read_csv(\"final position group data/final_qb_data.csv\")\n",
    "dfFantasy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "numeric_cols = dfFantasy.select_dtypes(include=[np.number]).columns\n",
    "for column in numeric_cols:\n",
    "    dfFantasy[column].fillna(dfFantasy[column].mean(), inplace=True)\n",
    "dfGrades = pd.read_csv(\"approximate value data/AVbyPositionGroup.csv\")\n",
    "\n",
    "def correctData(df, pprTF):\n",
    "  #cols to make per game\n",
    "  cols = ['completions', 'attempts', 'passing_yards',\n",
    "       'passing_tds', 'interceptions', 'sacks',\n",
    "       'sack_fumbles_lost', 'passing_air_yards', 'passing_yards_after_catch',\n",
    "       'passing_first_downs', 'passing_2pt_conversions',\n",
    "       'carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "       'rushing_2pt_conversions', 'fantasy_points', 'age']\n",
    "\n",
    "  #basing data if ppr or not\n",
    "  if pprTF == 2:\n",
    "    pass\n",
    "  elif pprTF == 0:\n",
    "    pass\n",
    "  elif pprTF == 1:\n",
    "    pass\n",
    "\n",
    "    \n",
    "  #adding ppg column\n",
    "  df.loc[:, 'PPG'] = df['fantasy_points'] / df['GP']\n",
    "\n",
    "\n",
    "  #make all columns in a per game basis\n",
    "  for col in cols:\n",
    "    df.loc[:, col] = df[col] / df['GP'] \n",
    "\n",
    "\n",
    "  #only players with more than 7 games.\n",
    "  df = df[df.GP > 7]\n",
    "  df = df[df.fantasy_points >= 0]\n",
    "\n",
    "  df = df[df.PPG > 5]\n",
    "  \n",
    "\n",
    "  return df\n",
    "\n",
    "#removes unneccesary stats\n",
    "def removeUnwanted(dfPos, pos):\n",
    "  dfPos = dfPos.drop(columns=['season',\"GP\", \"season_type\", \"fantasy_points\", \"player_display_name\", \"player_id\", \"team\", \"position\"])\n",
    "  return dfPos\n",
    "\n",
    "#shifts data forward one year\n",
    "def makeCorrectShift(df):\n",
    "  shifters = ['PPG','season','GP','season_type','age','fantasy_points','completions','attempts','passing_yards','passing_tds','interceptions','sacks','sack_fumbles_lost','passing_air_yards','passing_yards_after_catch','passing_first_downs','passing_2pt_conversions','carries','rushing_yards','rushing_tds','rushing_fumbles_lost','rushing_first_downs','rushing_2pt_conversions']\n",
    "  \n",
    "  #adds target variable\n",
    "  df[\"PPG\"] = df[\"PPG\"]\n",
    "  \n",
    "  #shifts it forward a year (for example 2011 goes to 2012)\n",
    "  df[shifters] = df.groupby('player_display_name')[shifters].shift(1)\n",
    "  df = df.dropna()\n",
    "\n",
    "  return df\n",
    "\n",
    "#where machine learning is done. returns the model and score.\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def machineLearning(df, arr, dictParam):\n",
    "    # Define predictors excluding the target variable\n",
    "    predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "\n",
    "    # Split the data\n",
    "    x = df[predictors].values\n",
    "    y = df[\"PPG\"].values\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Initialize and train GradientBoostingRegressor\n",
    "    gbr = GradientBoostingRegressor(**dictParam)\n",
    "    gbr.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predict_test = gbr.predict(x_test)\n",
    "    mae = mean_absolute_error(y_test, predict_test)\n",
    "\n",
    "    predict_test_unscaled = predict_test * (arr[1] - arr[0]) + arr[0]\n",
    "    y_test_unscaled = y_test * (arr[1] - arr[0]) + arr[0]\n",
    "\n",
    "    # Calculate permutation importance\n",
    "    r = permutation_importance(gbr, x_test, y_test, n_repeats=100, random_state=0)\n",
    "\n",
    "    # Organize importances\n",
    "    importance_dict = {name: score for name, score in zip(predictors, r.importances_mean)}\n",
    "    sorted_importances = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for feature, importance in sorted_importances:\n",
    "      print(f\"{feature}: {importance}\")\n",
    "\n",
    "\n",
    "    return [mae, gbr]\n",
    "\n",
    "# Example usage of the modified function\n",
    "\n",
    "\n",
    "def getBestParams(df, arr):\n",
    "\n",
    "  #make the predictors and data and test sets correctly\n",
    "  predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "  x = df[predictors].values\n",
    "  y = df[\"PPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  \n",
    "  #make the parameters to search over. for hidden_layer_sizes, I experimented with alot and the ones listed now is just final set of experiment.\n",
    "  \n",
    "  grid = {\n",
    "      'n_estimators': [100, 200, 300],\n",
    "      'learning_rate': [0.01, 0.1, 0.2],\n",
    "      'max_depth': [3, 4, 5],\n",
    "      'min_samples_split': [2, 3, 4]\n",
    "  }\n",
    "\n",
    "  #create an MLPRegressor object\n",
    "  gbr = GradientBoostingRegressor()\n",
    "\n",
    "  #create a GridSearchCV object and fit it to the training data\n",
    "  grid_search = GridSearchCV(gbr, param_grid=grid, cv=5, n_jobs=-1)\n",
    "  grid_search.fit(x_train, y_train)\n",
    "\n",
    "  #the best model to make predictions on the test data and evaluate performance\n",
    "  y_pred = grid_search.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale, uses a reverse of original formula\n",
    "  for i in range(len(y_pred)):\n",
    "    y_pred[i] = (y_pred[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "\n",
    "  print(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "  return grid_search.best_params_\n",
    "\n",
    "#gets original value for fantasy points for predictions.\n",
    "def getScaleBack(df):\n",
    "  #index of column\n",
    "  column_index = df.columns.get_loc(\"PPG\")\n",
    "\n",
    "  #min value of column:\n",
    "  min_value = df[\"PPG\"].min()\n",
    "\n",
    "  #scaling valye of column\n",
    "  #scaling_factor = scaler.scale_[column_index]\n",
    "  max_value = df[\"PPG\"].max()\n",
    "\n",
    "  #array to be used later to scale each data\n",
    "  arr = [min_value, max_value]\n",
    "\n",
    "  return arr\n",
    "\n",
    "def test(df, model, arr):\n",
    "  #make columns everything but target\n",
    "  predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "\n",
    "\n",
    "  #make train and test sets\n",
    "  x = df[predictors].values\n",
    "  y = df[\"PPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  #make the predictions\n",
    "  predict_test = model.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale by reversing formula\n",
    "  for i in range(len(predict_test)):\n",
    "    predict_test[i] = (predict_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "  #average error \n",
    "  mae = mean_absolute_error(y_test, predict_test)\n",
    "  print(\"test \", mae)\n",
    "\n",
    "#if ppr is 0, than it is non ppr. if 1, then it is half ppr. if 2, full ppr. loops through each.\n",
    "for ppr in [0,1,2]:\n",
    "\n",
    "  dfFantasyCopy = dfFantasy.copy()\n",
    "\n",
    "  dfFantasyCopy = correctData(dfFantasyCopy, ppr)\n",
    "\n",
    "  dfFantasyCopy = makeCorrectShift(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.loc[dfFantasyCopy[\"season\"] != 2012]\n",
    "\n",
    "  dfFantasyCopy = removeUnwanted(dfFantasyCopy, \"QB\")\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.reset_index(drop=True)\n",
    "\n",
    "  #gets fantasy_points_ppr scale per each position\n",
    "  scaleQB = getScaleBack(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy[dfFantasyCopy.columns] = scaler.fit_transform(dfFantasyCopy[dfFantasyCopy.columns])\n",
    "\n",
    "  #obtained by running the getBestParams function per each respective position\n",
    "  paramQB = getBestParams(dfFantasyCopy, scaleQB)\n",
    "\n",
    "  #makes array of model and score, then prints it\n",
    "  qbArray = machineLearning(dfFantasyCopy, scaleQB, paramQB)\n",
    "  num = qbArray[0]\n",
    "  qbModel = qbArray[1]\n",
    "  print(\"qb score(ppg off on average per player): \", num)\n",
    "\n",
    "  if ppr == 0:\n",
    "      joblib.dump(qbModel, \"qb models/qbModelNonPPR.joblib\")\n",
    "  elif ppr == 1:\n",
    "      joblib.dump(qbModel, \"qb models/qbModelHalfPPR.joblib\")\n",
    "  elif ppr == 2:\n",
    "      joblib.dump(qbModel, \"qb models/qbModelPPR.joblib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rushing_yards: 0.20281412036782837\n",
      "rb: 0.08913783341599844\n",
      "carries: 0.040875710974054416\n",
      "rushing_first_downs: 0.017864461816411457\n",
      "rushing_fumbles_lost: 0.00420155980055692\n",
      "dst: 0.0029457834557763507\n",
      "wrte: 0.0014086212737451798\n",
      "rrtd: 0.0008177730913153081\n",
      "rushing_tds: 0.00015068693383714306\n",
      "special_teams_tds: 0.00014294052556384162\n",
      "receiving_yards: 8.044928364969617e-05\n",
      "rushing_2pt_conversions: 0.0\n",
      "receiving_fumbles_lost: 0.0\n",
      "receiving_2pt_conversions: 0.0\n",
      "qb: -0.00016302263892763568\n",
      "receiving_tds: -0.0014143564840335798\n",
      "oline: -0.001982430443263473\n",
      "targets: -0.007451721407986442\n",
      "receiving_air_yards: -0.0076191445454837315\n",
      "receptions: -0.010498652240841597\n",
      "receiving_yards_after_catch: -0.012634756744631149\n",
      "receiving_first_downs: -0.028722071952736076\n",
      "age: -0.032580616170340464\n",
      "rb score(ppg off on average per player):  0.13962562375378734\n",
      "rushing_yards: 0.21875678569388363\n",
      "rb: 0.038127420233495586\n",
      "age: 0.034651919024522845\n",
      "rushing_first_downs: 0.025239581038271043\n",
      "rrtd: 0.017719484140307898\n",
      "receiving_first_downs: 0.016729769651547332\n",
      "receiving_yards_after_catch: 0.016713407090359084\n",
      "rushing_tds: 0.015424911422783247\n",
      "receptions: 0.01479926019435327\n",
      "carries: 0.010683234818944287\n",
      "rushing_fumbles_lost: 0.009826187264130655\n",
      "dst: 0.004097600471877865\n",
      "receiving_yards: 0.002779552921697229\n",
      "targets: 0.0004638550208027503\n",
      "special_teams_tds: 0.0003056222362252814\n",
      "receiving_fumbles_lost: 0.0\n",
      "receiving_2pt_conversions: 0.0\n",
      "rushing_2pt_conversions: -3.206305713317259e-05\n",
      "receiving_air_yards: -0.0003711335860147991\n",
      "qb: -0.0017015118056267165\n",
      "wrte: -0.001973968524000178\n",
      "receiving_tds: -0.0029561034822306155\n",
      "oline: -0.005136685915390118\n",
      "rb score(ppg off on average per player):  0.1269123997811612\n",
      "rushing_yards: 0.13465948821760546\n",
      "rushing_first_downs: 0.0876753282949044\n",
      "rrtd: 0.02772248823190271\n",
      "rb: 0.024919469018557683\n",
      "oline: 0.012379202314332849\n",
      "receiving_yards_after_catch: 0.01051649381436321\n",
      "receiving_first_downs: 0.008612392927516014\n",
      "qb: 0.007827056949266172\n",
      "wrte: 0.006537720327468247\n",
      "dst: 0.0030320797715574555\n",
      "carries: 0.0029483425733402425\n",
      "rushing_tds: 0.002438989797179968\n",
      "age: 0.001747048392745175\n",
      "receiving_air_yards: 0.0016806371256133745\n",
      "receiving_fumbles_lost: 0.0\n",
      "receiving_2pt_conversions: 0.0\n",
      "special_teams_tds: 0.0\n",
      "receiving_tds: -6.622153777281258e-05\n",
      "targets: -0.0010787657493564972\n",
      "rushing_2pt_conversions: -0.002145463310755499\n",
      "receiving_yards: -0.005334252929607133\n",
      "rushing_fumbles_lost: -0.005727404182586409\n",
      "receptions: -0.007391604804020815\n",
      "rb score(ppg off on average per player):  0.12321064179318898\n"
     ]
    }
   ],
   "source": [
    "#RB ML MODEL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "\n",
    "#scaler to scale data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#read csv files into pandas\n",
    "dfFantasy = pd.read_csv(\"final position group data/final_rb_data.csv\")\n",
    "dfFantasy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "numeric_cols = dfFantasy.select_dtypes(include=[np.number]).columns\n",
    "for column in numeric_cols:\n",
    "    dfFantasy[column].fillna(dfFantasy[column].mean(), inplace=True)\n",
    "dfGrades = pd.read_csv(\"approximate value data/AVbyPositionGroup.csv\")\n",
    "\n",
    "def correctData(df, pprTF):\n",
    "  #cols to make per game\n",
    "  cols = ['carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs', 'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs',\n",
    "       'receiving_2pt_conversions', 'special_teams_tds', 'fantasy_points', 'rrtd', 'age']\n",
    "\n",
    "  #basing data if ppr or not\n",
    "  if pprTF == 2:\n",
    "    pass\n",
    "  elif pprTF == 0:\n",
    "    df.loc[:, \"fantasy_points\"] = df[\"fantasy_points\"] - df[\"receptions\"]\n",
    "  elif pprTF == 1:\n",
    "    df.loc[:, \"fantasy_points\"] = df[\"fantasy_points\"] - (df[\"receptions\"]/2)\n",
    "\n",
    "    \n",
    "  #adding ppg column\n",
    "  df.loc[:, 'PPG'] = df['fantasy_points'] / df['GP']\n",
    "\n",
    "\n",
    "  #make all columns in a per game basis\n",
    "  for col in cols:\n",
    "    df.loc[:, col] = df[col] / df['GP'] \n",
    "\n",
    "\n",
    "  #only players with more than 7 games.\n",
    "  df = df[df.GP > 7]\n",
    "  df = df[df.fantasy_points >= 0]\n",
    "\n",
    "  df = df[df.PPG > 2]\n",
    "  \n",
    "\n",
    "  return df\n",
    "\n",
    "#removes unneccesary stats\n",
    "def removeUnwanted(dfPos, pos):\n",
    "  dfPos = dfPos.drop(columns=['season',\"GP\", \"season_type\", \"fantasy_points\", \"player_display_name\", \"player_id\", \"team\", \"position\"])\n",
    "  return dfPos\n",
    "\n",
    "#shifts data forward one year\n",
    "def makeCorrectShift(df):\n",
    "  shifters = ['player_id', 'season', 'player_display_name', 'team', 'GP', 'position',\n",
    "       'age','season_type', 'carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "       'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs',\n",
    "       'receiving_2pt_conversions', 'special_teams_tds', 'fantasy_points',\n",
    "       'rrtd']\n",
    "  \n",
    "  #adds target variable\n",
    "  df[\"PPG\"] = df[\"PPG\"]\n",
    "  \n",
    "  #shifts it forward a year (for example 2011 goes to 2012)\n",
    "  df[shifters] = df.groupby('player_display_name')[shifters].shift(1)\n",
    "  df = df.dropna()\n",
    "\n",
    "  return df\n",
    "\n",
    "#where machine learning is done. returns the model and score.\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def machineLearning(df, arr, dictParam):\n",
    "    # Define predictors excluding the target variable\n",
    "    predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "\n",
    "    # Split the data\n",
    "    x = df[predictors].values\n",
    "    y = df[\"PPG\"].values\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Initialize and train GradientBoostingRegressor\n",
    "    gbr = GradientBoostingRegressor(**dictParam)\n",
    "    gbr.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predict_test = gbr.predict(x_test)\n",
    "    mae = mean_absolute_error(y_test, predict_test)\n",
    "\n",
    "    predict_test_unscaled = predict_test * (arr[1] - arr[0]) + arr[0]\n",
    "    y_test_unscaled = y_test * (arr[1] - arr[0]) + arr[0]\n",
    "\n",
    "    # print(\"Predicted vs Actual PPG (unscaled):\")\n",
    "    # for pred, actual in zip(predict_test_unscaled, y_test_unscaled):\n",
    "    #     print(f\"Predicted: {pred:.2f}, Actual: {actual:.2f}\")\n",
    "\n",
    "    # Calculate permutation importance\n",
    "    r = permutation_importance(gbr, x_test, y_test, n_repeats=100, random_state=0)\n",
    "\n",
    "    # Organize importances\n",
    "    importance_dict = {name: score for name, score in zip(predictors, r.importances_mean)}\n",
    "    sorted_importances = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for feature, importance in sorted_importances:\n",
    "        print(f\"{feature}: {importance}\")\n",
    "    \n",
    "\n",
    "\n",
    "    return [mae, gbr, sorted_importances]\n",
    "\n",
    "# Example usage of the modified function\n",
    "\n",
    "\n",
    "def getBestParams(df, arr):\n",
    "\n",
    "  #make the predictors and data and test sets correctly\n",
    "  predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "  x = df[predictors].values\n",
    "  y = df[\"PPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  \n",
    "  #make the parameters to search over. for hidden_layer_sizes, I experimented with alot and the ones listed now is just final set of experiment.\n",
    "  \n",
    "  grid = {\n",
    "      'n_estimators': [100, 200, 300],\n",
    "      'learning_rate': [0.01, 0.1, 0.2],\n",
    "      'max_depth': [3, 4, 5],\n",
    "      'min_samples_split': [2, 3, 4]\n",
    "  }\n",
    "\n",
    "  #create an MLPRegressor object\n",
    "  gbr = GradientBoostingRegressor()\n",
    "\n",
    "  #create a GridSearchCV object and fit it to the training data\n",
    "  grid_search = GridSearchCV(gbr, param_grid=grid, cv=5, n_jobs=-1)\n",
    "  grid_search.fit(x_train, y_train)\n",
    "\n",
    "  #the best model to make predictions on the test data and evaluate performance\n",
    "  y_pred = grid_search.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale, uses a reverse of original formula\n",
    "  for i in range(len(y_pred)):\n",
    "    y_pred[i] = (y_pred[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "\n",
    "  # print(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "  return grid_search.best_params_\n",
    "\n",
    "#gets original value for fantasy points for predictions.\n",
    "def getScaleBack(df):\n",
    "  #index of column\n",
    "  column_index = df.columns.get_loc(\"PPG\")\n",
    "\n",
    "  #min value of column:\n",
    "  min_value = df[\"PPG\"].min()\n",
    "\n",
    "  #scaling valye of column\n",
    "  #scaling_factor = scaler.scale_[column_index]\n",
    "  max_value = df[\"PPG\"].max()\n",
    "\n",
    "  #array to be used later to scale each data\n",
    "  arr = [min_value, max_value]\n",
    "\n",
    "  return arr\n",
    "\n",
    "def test(df, model, arr):\n",
    "  #make columns everything but target\n",
    "  predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "\n",
    "\n",
    "  #make train and test sets\n",
    "  x = df[predictors].values\n",
    "  y = df[\"PPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  #make the predictions\n",
    "  predict_test = model.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale by reversing formula\n",
    "  for i in range(len(predict_test)):\n",
    "    predict_test[i] = (predict_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "  #average error \n",
    "  mae = mean_absolute_error(y_test, predict_test)\n",
    "  print(\"test \", mae)\n",
    "\n",
    "#if ppr is 0, than it is non ppr. if 1, then it is half ppr. if 2, full ppr. loops through each.\n",
    "for ppr in [0,1,2]:\n",
    "\n",
    "  dfFantasyCopy = dfFantasy.copy()\n",
    "\n",
    "  dfFantasyCopy = correctData(dfFantasyCopy, ppr)\n",
    "\n",
    "  dfFantasyCopy = makeCorrectShift(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.loc[dfFantasyCopy[\"season\"] != 2012]\n",
    "\n",
    "  dfFantasyCopy = removeUnwanted(dfFantasyCopy, \"RB\")\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.reset_index(drop=True)\n",
    "\n",
    "  #gets fantasy_points_ppr scale per each position\n",
    "  scaleRB = getScaleBack(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy[dfFantasyCopy.columns] = scaler.fit_transform(dfFantasyCopy[dfFantasyCopy.columns])\n",
    "\n",
    "  #obtained by running the getBestParams function per each respective position\n",
    "  paramRB = getBestParams(dfFantasyCopy, scaleRB)\n",
    "\n",
    "  #makes array of model and score, then prints it\n",
    "  rbArray = machineLearning(dfFantasyCopy, scaleRB, paramRB)\n",
    "  num = rbArray[0]\n",
    "  rbModel = rbArray[1]\n",
    "\n",
    "  print(\"rb score(ppg off on average per player): \", num)\n",
    "  if ppr == 0:\n",
    "      joblib.dump(rbModel, \"rb models/rbModelNonPPR.joblib\")\n",
    "  elif ppr == 1:\n",
    "      joblib.dump(rbModel, \"rb models/rbModelHalfPPR.joblib\")\n",
    "  elif ppr == 2:\n",
    "      joblib.dump(rbModel, \"rb models/rbModelPPR.joblib\")\n",
    "#print(dfFantasyRB.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "receiving_air_yards: 0.1252131697268834\n",
      "receiving_yards_after_catch: 0.11004595216920647\n",
      "qb: 0.03231817528397688\n",
      "wrte: 0.02988979714896725\n",
      "targets: 0.028040083461295245\n",
      "oline: 0.013920920690549454\n",
      "receiving_fumbles_lost: 0.007687972869702055\n",
      "receiving_first_downs: 0.0026183161429095625\n",
      "receiving_2pt_conversions: 0.0007581389399461146\n",
      "dst: 0.00023813778888016836\n",
      "rushing_fumbles_lost: 0.0\n",
      "rushing_2pt_conversions: 0.0\n",
      "special_teams_tds: 0.0\n",
      "carries: -0.000656084341637837\n",
      "rushing_first_downs: -0.0012753596261482513\n",
      "rrtd: -0.002586166316200752\n",
      "receiving_tds: -0.0037045193976893574\n",
      "receiving_yards: -0.004570537246859706\n",
      "rushing_yards: -0.006044676303863912\n",
      "age: -0.006385783015300411\n",
      "rushing_tds: -0.010757737786323855\n",
      "rb: -0.012037887085616879\n",
      "receptions: -0.01549237534816152\n",
      "wrte score(ppg off on average per player):  0.11532339659903262\n",
      "receiving_yards: 0.16056983093517915\n",
      "receiving_air_yards: 0.14296319183221415\n",
      "qb: 0.02734837809713282\n",
      "receiving_yards_after_catch: 0.021551770212817022\n",
      "wrte: 0.013775678817100507\n",
      "receiving_first_downs: 0.013671554310642632\n",
      "receptions: 0.013078981581385905\n",
      "age: 0.008269881190447158\n",
      "targets: 0.005186018977958557\n",
      "dst: 0.0037609937447242205\n",
      "oline: 0.0028953000134910047\n",
      "receiving_fumbles_lost: 0.0023517880445900184\n",
      "receiving_2pt_conversions: 0.0014926756624587157\n",
      "rushing_yards: 0.001020561018791526\n",
      "carries: 0.0004260695901695522\n",
      "rushing_tds: 0.00042031521741831446\n",
      "rushing_fumbles_lost: 0.0001545450680908722\n",
      "rrtd: 2.5678286003536498e-05\n",
      "rushing_2pt_conversions: 0.0\n",
      "special_teams_tds: 0.0\n",
      "rushing_first_downs: -0.0012588760430627965\n",
      "rb: -0.0015917222069082504\n",
      "receiving_tds: -0.0031043154651012005\n",
      "wrte score(ppg off on average per player):  0.11093880679345816\n",
      "receiving_yards: 0.34654758359909155\n",
      "receiving_air_yards: 0.07292917922943691\n",
      "age: 0.013708045753149363\n",
      "receptions: 0.013082408463129153\n",
      "receiving_yards_after_catch: 0.011672168026399352\n",
      "targets: 0.011578504030960904\n",
      "wrte: 0.00988803726952314\n",
      "qb: 0.007301092583019202\n",
      "rushing_yards: 0.004320324054536572\n",
      "receiving_first_downs: 0.004057209594231237\n",
      "receiving_tds: 0.003025568970499635\n",
      "carries: 0.0026038219011638554\n",
      "rrtd: 0.002437038847160995\n",
      "rb: 0.0006384518060310795\n",
      "oline: 0.00033874174518418453\n",
      "rushing_fumbles_lost: 0.00028882415079770963\n",
      "receiving_fumbles_lost: 4.424997950223663e-05\n",
      "receiving_2pt_conversions: 1.3158764134338919e-05\n",
      "rushing_2pt_conversions: 0.0\n",
      "special_teams_tds: 0.0\n",
      "rushing_first_downs: -0.0003798936611739501\n",
      "rushing_tds: -0.001035026961411577\n",
      "dst: -0.0023636222847164155\n",
      "wrte score(ppg off on average per player):  0.10712789081330425\n"
     ]
    }
   ],
   "source": [
    "#WRTE ML MODEL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "\n",
    "#scaler to scale data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#read csv files into pandas\n",
    "dfFantasy = pd.read_csv(\"final position group data/final_wrte_data.csv\")\n",
    "dfFantasy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "numeric_cols = dfFantasy.select_dtypes(include=[np.number]).columns\n",
    "for column in numeric_cols:\n",
    "    dfFantasy[column].fillna(dfFantasy[column].mean(), inplace=True)\n",
    "dfGrades = pd.read_csv(\"approximate value data/AVbyPositionGroup.csv\")\n",
    "\n",
    "def correctData(df, pprTF):\n",
    "  #cols to make per game\n",
    "  cols = ['carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs', 'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs',\n",
    "       'receiving_2pt_conversions', 'special_teams_tds', 'fantasy_points', 'rrtd', 'age']\n",
    "\n",
    "  #basing data if ppr or not\n",
    "  if pprTF == 2:\n",
    "    pass\n",
    "  elif pprTF == 0:\n",
    "    df.loc[:, \"fantasy_points\"] = df[\"fantasy_points\"] - df[\"receptions\"]\n",
    "  elif pprTF == 1:\n",
    "    df.loc[:, \"fantasy_points\"] = df[\"fantasy_points\"] - (df[\"receptions\"]/2)\n",
    "\n",
    "    \n",
    "  #adding ppg column\n",
    "  df.loc[:, 'PPG'] = df['fantasy_points'] / df['GP']\n",
    "\n",
    "\n",
    "  #make all columns in a per game basis\n",
    "  for col in cols:\n",
    "    df.loc[:, col] = df[col] / df['GP'] \n",
    "\n",
    "\n",
    "  #only players with more than 7 games.\n",
    "  df = df[df.GP > 7]\n",
    "  df = df[df.fantasy_points >= 0]\n",
    "\n",
    "  df = df[df.PPG > 2]\n",
    "  \n",
    "\n",
    "  return df\n",
    "\n",
    "#removes unneccesary stats\n",
    "def removeUnwanted(dfPos, pos):\n",
    "  dfPos = dfPos.drop(columns=['season',\"GP\", \"season_type\", \"fantasy_points\", \"player_display_name\", \"player_id\", \"team\", \"position\"])\n",
    "  return dfPos\n",
    "\n",
    "#shifts data forward one year\n",
    "def makeCorrectShift(df):\n",
    "  shifters = ['player_id', 'season', 'player_display_name', 'team', 'GP', 'position',\n",
    "       'age', 'season_type', 'carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "       'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs',\n",
    "       'receiving_2pt_conversions', 'special_teams_tds', 'fantasy_points',\n",
    "       'rrtd']\n",
    "  \n",
    "  #adds target variable\n",
    "  df[\"PPG\"] = df[\"PPG\"]\n",
    "  \n",
    "  #shifts it forward a year (for example 2011 goes to 2012)\n",
    "  df[shifters] = df.groupby('player_display_name')[shifters].shift(1)\n",
    "  df = df.dropna()\n",
    "\n",
    "  return df\n",
    "\n",
    "#where machine learning is done. returns the model and score.\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def machineLearning(df, arr, dictParam):\n",
    "    # Define predictors excluding the target variable\n",
    "    predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "\n",
    "    # Split the data\n",
    "    x = df[predictors].values\n",
    "    y = df[\"PPG\"].values\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Initialize and train MLPRegressor\n",
    "    gbr = GradientBoostingRegressor(**dictParam)\n",
    "    gbr.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predict_test = gbr.predict(x_test)\n",
    "    mae = mean_absolute_error(y_test, predict_test)\n",
    "\n",
    "    predict_test_unscaled = predict_test * (arr[1] - arr[0]) + arr[0]\n",
    "    y_test_unscaled = y_test * (arr[1] - arr[0]) + arr[0]\n",
    "\n",
    "    # print(\"Predicted vs Actual PPG (unscaled):\")\n",
    "    # for pred, actual in zip(predict_test_unscaled, y_test_unscaled):\n",
    "    #     print(f\"Predicted: {pred:.2f}, Actual: {actual:.2f}\")\n",
    "\n",
    "    # Calculate permutation importance\n",
    "    r = permutation_importance(gbr, x_test, y_test, n_repeats=100, random_state=0)\n",
    "\n",
    "    # Organize importances\n",
    "    importance_dict = {name: score for name, score in zip(predictors, r.importances_mean)}\n",
    "    sorted_importances = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Print sorted importances\n",
    "    for feature, importance in sorted_importances:\n",
    "        print(f\"{feature}: {importance}\")\n",
    "    \n",
    "\n",
    "\n",
    "    return [mae, gbr, sorted_importances]\n",
    "\n",
    "# Example usage of the modified function\n",
    "\n",
    "\n",
    "def getBestParams(df, arr):\n",
    "\n",
    "  #make the predictors and data and test sets correctly\n",
    "  predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "  x = df[predictors].values\n",
    "  y = df[\"PPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  \n",
    "  #make the parameters to search over. for hidden_layer_sizes, I experimented with alot and the ones listed now is just final set of experiment.\n",
    "  \n",
    "  grid = {\n",
    "      'n_estimators': [100, 200, 300],\n",
    "      'learning_rate': [0.01, 0.1, 0.2],\n",
    "      'max_depth': [3, 4, 5],\n",
    "      'min_samples_split': [2, 3, 4]\n",
    "  }\n",
    "\n",
    "  #create an MLPRegressor object\n",
    "  gbr = GradientBoostingRegressor()\n",
    "\n",
    "  #create a GridSearchCV object and fit it to the training data\n",
    "  grid_search = GridSearchCV(gbr, param_grid=grid, cv=5, n_jobs=-1)\n",
    "  grid_search.fit(x_train, y_train)\n",
    "\n",
    "  #the best model to make predictions on the test data and evaluate performance\n",
    "  y_pred = grid_search.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale, uses a reverse of original formula\n",
    "  for i in range(len(y_pred)):\n",
    "    y_pred[i] = (y_pred[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "\n",
    "  # print(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "  return grid_search.best_params_\n",
    "\n",
    "#gets original value for fantasy points for predictions.\n",
    "def getScaleBack(df):\n",
    "  #index of column\n",
    "  column_index = df.columns.get_loc(\"PPG\")\n",
    "\n",
    "  #min value of column:\n",
    "  min_value = df[\"PPG\"].min()\n",
    "\n",
    "  #scaling valye of column\n",
    "  #scaling_factor = scaler.scale_[column_index]\n",
    "  max_value = df[\"PPG\"].max()\n",
    "\n",
    "  #array to be used later to scale each data\n",
    "  arr = [min_value, max_value]\n",
    "\n",
    "  return arr\n",
    "\n",
    "def test(df, model, arr):\n",
    "  #make columns everything but target\n",
    "  predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "\n",
    "\n",
    "  #make train and test sets\n",
    "  x = df[predictors].values\n",
    "  y = df[\"PPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  #make the predictions\n",
    "  predict_test = model.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale by reversing formula\n",
    "  for i in range(len(predict_test)):\n",
    "    predict_test[i] = (predict_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "  #average error \n",
    "  mae = mean_absolute_error(y_test, predict_test)\n",
    "  # print(\"test \", mae)\n",
    "\n",
    "#if ppr is 0, than it is non ppr. if 1, then it is half ppr. if 2, full ppr. loops through each.\n",
    "for ppr in [0,1,2]:\n",
    "\n",
    "  dfFantasyCopy = dfFantasy.copy()\n",
    "\n",
    "  dfFantasyCopy = correctData(dfFantasyCopy, ppr)\n",
    "  \n",
    "  dfFantasyCopy = makeCorrectShift(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.loc[dfFantasyCopy[\"season\"] != 2012]\n",
    "\n",
    "  dfFantasyCopy = removeUnwanted(dfFantasyCopy, \"WRTE\")\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.reset_index(drop=True)\n",
    "\n",
    "  #gets fantasy_points_ppr scale per each position\n",
    "  scaleWRTE = getScaleBack(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy[dfFantasyCopy.columns] = scaler.fit_transform(dfFantasyCopy[dfFantasyCopy.columns])\n",
    "\n",
    "  #obtained by running the getBestParams function per each respective position\n",
    "  paramWRTE = getBestParams(dfFantasyCopy, scaleWRTE)\n",
    "\n",
    "  #makes array of model and score, then prints it\n",
    "  wrteArray = machineLearning(dfFantasyCopy, scaleWRTE, paramWRTE)\n",
    "  num = wrteArray[0]\n",
    "  wrteModel = wrteArray[1]\n",
    "\n",
    "  print(\"wrte score(ppg off on average per player): \", num)\n",
    "  if ppr == 0:\n",
    "      joblib.dump(wrteModel, \"wrte models/wrteModelNonPPR.joblib\")\n",
    "  elif ppr == 1:\n",
    "      joblib.dump(wrteModel, \"wrte models/wrteModelHalfPPR.joblib\")\n",
    "  elif ppr == 2:\n",
    "      joblib.dump(wrteModel, \"wrte models/wrteModelPPR.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
